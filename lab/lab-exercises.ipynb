{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Consider the following data:\n",
    "\n",
    "| Tid | Refund | Marital Status | Taxable Income (K) | Cheat |\n",
    "|-----|--------|----------------|--------------------|-------|\n",
    "| 1   | Yes    | Single         | 125                | No    |\n",
    "| 2   | No     | Married        | 100                | No    |\n",
    "| 3   | No     | Single         | 70                 | No    |\n",
    "| 4   | Yes    | Married        | 120                | No    |\n",
    "| 5   | No     | Divorced       | 95                 | Yes   |\n",
    "| 6   | No     | Married        | 60                 | No    |\n",
    "| 7   | Yes    | Divorced       | 220                | No    |\n",
    "| 8   | No     | Single         | 85                 | Yes   |\n",
    "| 9   | No     | Married        | 75                 | No    |\n",
    "| 10  | No     | Single         | 90                 | Yes   |\n",
    "\n",
    "Complete the code below to find the best split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data provided\n",
    "data = {\n",
    "    'Tid': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Refund': ['Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No'],\n",
    "    'Marital Status': ['Single', 'Married', 'Single', 'Married', 'Divorced', 'Married', 'Divorced', 'Single', 'Married', 'Single'],\n",
    "    'Taxable Income (K)': [125, 100, 70, 120, 95, 60, 220, 85, 75, 90],\n",
    "    'Cheat': ['No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# @TODO Function to calculate Gini impurity\n",
    "def gini_impurity(groups, classes):\n",
    "    pass\n",
    "\n",
    "\n",
    "# @TODO Function to split a dataset based on a column and a value\n",
    "# Should return a tuple of left and right arrays\n",
    "# For numeric columns, left should be <= the value\n",
    "# For categorical columns, left should be == the value\n",
    "def test_split(column, value, dataset):\n",
    "    left, right = [], []\n",
    "    #YOUR CODE HERE\n",
    "    return left, right\n",
    "\n",
    "# Function to get quartiles for continuous variables\n",
    "def get_quartiles(series):\n",
    "    return np.percentile(series, [25, 50, 75])\n",
    "\n",
    "# Function to find the best split\n",
    "def get_best_split(df_subset):\n",
    "    dataset = df_subset.values.tolist()  # Convert dataframe subset to list of lists\n",
    "    class_values = list(df_subset['Cheat'].unique())  # Unique class labels in this subset\n",
    "    best_column, best_value, best_gini, best_groups = None, None, float('inf'), None\n",
    "    \n",
    "    # Iterate over each column (feature)\n",
    "    for column in df_subset.columns[:-1]:  # Exclude the target variable 'Cheat'\n",
    "        if df_subset[column].dtype == 'object':  # Categorical column\n",
    "            unique_values = df_subset[column].unique()\n",
    "            for value in unique_values:\n",
    "                groups = test_split(df_subset.columns.get_loc(column), value, dataset)\n",
    "                if len(groups[0]) == 0 or len(groups[1]) == 0:\n",
    "                    continue\n",
    "                gini = gini_impurity(groups, class_values)\n",
    "                if gini < best_gini:\n",
    "                    best_column, best_value, best_gini, best_groups = column, value, gini, groups\n",
    "        \n",
    "        elif np.issubdtype(df_subset[column].dtype, np.number):  # Numeric column\n",
    "            # Use quartiles of the current subset\n",
    "            quartiles = get_quartiles(df_subset[column])\n",
    "            for value in quartiles:  # Try splitting by quartiles\n",
    "                groups = test_split(df_subset.columns.get_loc(column), value, dataset)\n",
    "                if len(groups[0]) == 0 or len(groups[1]) == 0:\n",
    "                    continue\n",
    "                gini = gini_impurity(groups, class_values)\n",
    "                if gini < best_gini:\n",
    "                    best_column, best_value, best_gini, best_groups = column, value, gini, groups\n",
    "    \n",
    "    return {'column': best_column, 'value': best_value, 'gini': best_gini, 'groups': best_groups}\n",
    "\n",
    "# Function to split a DataFrame based on a column and value\n",
    "def split_dataframe(df_subset, column, value):\n",
    "    \"\"\"Split a DataFrame into two based on a column and value\"\"\"\n",
    "    if isinstance(value, (int, float)):\n",
    "        left = df_subset[df_subset[column] <= value]\n",
    "        right = df_subset[df_subset[column] > value]\n",
    "    else:\n",
    "        left = df_subset[df_subset[column] == value]\n",
    "        right = df_subset[df_subset[column] != value]\n",
    "    return left, right\n",
    "\n",
    "\n",
    "\n",
    "# Call the function to find the best split\n",
    "best_split = get_best_split(df)\n",
    "print('Best Split: Column', best_split['column'], 'with value', best_split['value'], 'gini score =', best_split['gini'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Try using the preceding code to implement a complete decision tree algorithm! You will need to use a list to keep track of where you are in the tree.\n",
    "\n",
    "**Hint 1: Think of it like a \"to-do list\"**\n",
    "\n",
    "- Start with your full dataset as your first \"task\"\n",
    "- When you split a dataset, you create two new \"tasks\" (left and right groups)\n",
    "- Keep these tasks in a list - what happens when you add new tasks to the end and always work on the last task? Try it with a simple example on paper first!\n",
    "\n",
    "**Hint 2: What information do you need to remember?**\n",
    "\n",
    "For each \"task\" in your list, you'll need to track:\n",
    "\n",
    "- The subset of data you're working with\n",
    "- How deep you are in the tree (start at depth 0)\n",
    "- The conditions that got you here (like \"Refund == 'Yes' AND Income <= 85\")\n",
    "\n",
    "**Hint 3: When do you stop splitting?**\n",
    "\n",
    "Think about when it doesn't make sense to split further:\n",
    "\n",
    "- When all samples in a group have the same class (all \"Cheat\" or all \"Don't Cheat\")\n",
    "- When you've gone too deep (set a maximum depth like 3)\n",
    "- When you have too few samples to split meaningfully\n",
    "\n",
    "**Hint 4: Process one group completely before moving to another**\n",
    "\n",
    "- Use .pop() to take the last item from your to-do list\n",
    "- This naturally makes you finish one \"branch\" before starting another\n",
    "- When you can't split anymore, print out the rule you've discovered!\n",
    "\n",
    "**Hint 5: Building the rule strings**\n",
    "\n",
    "- As you go deeper, add conditions to a list: [\"Refund == 'Yes'\", \"Income <= 85\"]\n",
    "- When you reach a leaf (can't split anymore), combine them: \"IF Refund == 'Yes' AND Income <= 85 THEN Cheat = 'No'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple depth-first tree builder using DataFrame subsetting\n",
    "def build_tree_dfs(df, max_depth=3, min_samples=2):\n",
    "    \"\"\"Build a decision tree using a simple stack-based DFS approach\"\"\"\n",
    "    \n",
    "    # Initialize stack with: (df_subset, depth, path_conditions)\n",
    "    stack = []\n",
    "    stack.append((df, 0, []))\n",
    "    \n",
    "    rule_number = 1\n",
    "    \n",
    "    while stack:\n",
    "        df_subset, depth, conditions = stack.pop()\n",
    "        \n",
    "        # Get class distribution\n",
    "        class_counts = df_subset['Cheat'].value_counts().to_dict()\n",
    "        unique_classes = list(class_counts.keys())\n",
    "        \n",
    "        print(f\"\\n{'  ' * depth}Level {depth}: {len(df_subset)} samples\")\n",
    "        print(f\"{'  ' * depth}Class distribution: {class_counts}\")\n",
    "\n",
    "    # THE REST IS UP TO YOU!\n",
    "\n",
    "build_tree_dfs(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Build a decision tree to fit the [federalist papers](https://www.kaggle.com/datasets/tobyanderson/federalist-papers_) data, available in the data directory (click on the link to find out more information about this data). Note that you should restrict your analysis to papers by Hamilton or Madison.  Plot your training and test scores to pick a value for ccp_alpha. What did you pick?  Run your trained classifier on the \"disputed\" papers.  What does your model tell you? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
